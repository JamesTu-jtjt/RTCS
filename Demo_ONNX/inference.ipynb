{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3af35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "import onnx\n",
    "import cv2\n",
    "import torch\n",
    "import torch.onnx \n",
    "import os\n",
    "from importlib import reload  # Python 3.4+\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95fa9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(x,y):\n",
    "    bands = x.shape[2]\n",
    "    x = np.reshape(x, [-1, bands])\n",
    "    y = np.reshape(y, [-1, bands])\n",
    "    msr = np.mean((x-y)**2, 0)\n",
    "    maxval = np.max(y, 0)**2\n",
    "    return np.mean(10*np.log10(maxval/msr))\n",
    "\n",
    "def sam(x, y):\n",
    "    num = np.sum(np.multiply(x, y), 2)\n",
    "    den = np.sqrt(np.multiply(np.sum(x**2, 2), np.sum(y**2, 2)))\n",
    "    sam = np.sum(np.degrees(np.arccos(num / den))) / (x.shape[1]*x.shape[0])\n",
    "    return sam\n",
    "\n",
    "def rmse(x, y):\n",
    "    aux = (np.sum((y-x)**2, (0,1))) / (x.shape[0]*x.shape[1])\n",
    "    r = np.sqrt(np.mean(aux))\n",
    "    return r\n",
    "def awgn(x, snr):\n",
    "    x = torch.from_numpy(x).float()  \n",
    "    snr = 10 ** (snr / 10.0)\n",
    "    xpower = torch.sum(x ** 2) / x.numel()\n",
    "    npower = torch.sqrt(xpower / snr)\n",
    "    noisy_x = x + torch.randn(x.shape) * npower \n",
    "    return noisy_x.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5ace28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded_shape: (1, 27, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "#import encoder (SNR training strategy)\n",
    "##########################\n",
    "encoder = ort.InferenceSession('rtcs_ENCODER_SNR.onnx')\n",
    "##########################\n",
    "# input shape (full HSI) #\n",
    "##########################\n",
    "input_data = np.load('data/masked_CM/f090819t01p00r07rdn_b_ort_img_256.npy').astype(np.float32)\n",
    "#print(input_data.shape)\n",
    "##############################################################################\n",
    "#Percepted Stripe Input \n",
    "##############################################################################\n",
    "input_data = input_data[0:128,0:4,:]\n",
    "input_data = np.transpose(input_data, (2,0,1))\n",
    "input_data = input_data[np.newaxis,:,:,:]\n",
    "#print(input_data.shape)\n",
    "##############################################################################\n",
    "input_name = encoder.get_inputs()[0].name\n",
    "output_name = encoder.get_outputs()[0].name\n",
    "result = encoder.run([output_name], {input_name: input_data})\n",
    "encoded_result = np.array(result[0])\n",
    "encoded_result_shape = encoded_result.shape\n",
    "print(\"Encoded_shape:\", encoded_result_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "147e9fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded_shape: (1, 172, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# import decoder (SNR training strategy)\n",
    "##########################\n",
    "decoder = ort.InferenceSession('rtcs_DECODER_SNR.onnx')\n",
    "#input_data = np.random.randn(1, 27, 32, 1).astype(np.float32)  \n",
    "input_name = decoder.get_inputs()[0].name\n",
    "output_name = decoder.get_outputs()[0].name\n",
    "\n",
    "result = decoder.run([output_name], {input_name: encoded_result})\n",
    "decoded_result = np.array(result[0])\n",
    "original_shape = decoded_result.shape\n",
    "print(\"Decoded_shape:\", original_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa8706bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded_Decoded_output_shape: (1, 172, 128, 4)\n",
      "SAM: 1.9902306490166242 RMSE: 15.967152 PSNR: 47.819965\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# Encoder-Decoder (Full model) (SNR training strategy)\n",
    "##########################\n",
    "model = ort.InferenceSession('rtcs_ENCODER_DECODER_SNR.onnx')\n",
    "input_data = np.load('data/masked_CM/f090819t01p00r07rdn_b_ort_img_256.npy').astype(np.float32)\n",
    "#input_data = np.random.randn(1, 172, 128, 4).astype(np.float32)  \n",
    "input_data = input_data[0:128,0:4,:]\n",
    "input_data = np.transpose(input_data, (2,0,1))\n",
    "input_data = input_data[np.newaxis,:,:,:]\n",
    "input_name = model.get_inputs()[0].name\n",
    "output_name = model.get_outputs()[0].name\n",
    "result = model.run([output_name], {input_name: input_data})\n",
    "\n",
    "np_result = np.array(result[0])\n",
    "original_shape = np_result.shape\n",
    "print(\"Encoded_Decoded_output_shape:\", original_shape)\n",
    "print('SAM:',sam(input_data, np_result), 'RMSE:',(rmse(input_data, np_result)), 'PSNR:',psnr(input_data, np_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89fd557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded_shape: (1, 27, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "#import encoder (Mask training strategy)\n",
    "##########################\n",
    "encoder = ort.InferenceSession('rtcs_ENCODER_RM.onnx')\n",
    "##########################\n",
    "# input shape (full HSI) #\n",
    "##########################\n",
    "input_data = np.load('data/masked_CM/f090819t01p00r07rdn_b_ort_img_256.npy').astype(np.float32)\n",
    "#print(input_data.shape)\n",
    "##############################################################################\n",
    "#Percepted Stripe Input \n",
    "##############################################################################\n",
    "input_data = input_data[0:128,0:4,:]\n",
    "input_data = np.transpose(input_data, (2,0,1))\n",
    "input_data = input_data[np.newaxis,:,:,:]\n",
    "#print(input_data.shape) \n",
    "##############################################################################\n",
    "input_name = encoder.get_inputs()[0].name\n",
    "output_name = encoder.get_outputs()[0].name\n",
    "result = encoder.run([output_name], {input_name: input_data})\n",
    "encoded_result = np.array(result[0])\n",
    "encoded_result_shape = encoded_result.shape\n",
    "print(\"Encoded_shape:\", encoded_result_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14fc1ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded_shape: (1, 172, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# import decoder (Mask training strategy)\n",
    "##########################\n",
    "decoder = ort.InferenceSession('rtcs_DECODER_RM.onnx')\n",
    "#input_data = np.random.randn(1, 27, 32, 1).astype(np.float32)  \n",
    "input_name = decoder.get_inputs()[0].name\n",
    "output_name = decoder.get_outputs()[0].name\n",
    "result = decoder.run([output_name], {input_name: encoded_result})\n",
    "\n",
    "decoded_result = np.array(result[0])\n",
    "original_shape = decoded_result.shape\n",
    "print(\"Decoded_shape:\", original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d205bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded_Decoded_output_shape: (1, 172, 128, 4)\n",
      "SAM: 2.2291919796965844 RMSE: 18.649158 PSNR: 46.45769\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# Encoder-Decoder (Mask training strategy)\n",
    "##########################\n",
    "model = ort.InferenceSession('rtcs_ENCODER_DECODER_RM.onnx')\n",
    "input_data = np.load('data/masked_CM/f090819t01p00r07rdn_b_ort_img_256.npy').astype(np.float32)\n",
    "#input_data = np.random.randn(1, 172, 128, 4).astype(np.float32)  \n",
    "input_data = input_data[0:128,0:4,:]\n",
    "input_data = np.transpose(input_data, (2,0,1))\n",
    "input_data = input_data[np.newaxis,:,:,:]\n",
    "input_name = model.get_inputs()[0].name\n",
    "output_name = model.get_outputs()[0].name\n",
    "result = model.run([output_name], {input_name: input_data})\n",
    "\n",
    "np_result = np.array(result[0])\n",
    "original_shape = np_result.shape\n",
    "print(\"Encoded_Decoded_output_shape:\", original_shape)\n",
    "print('SAM:',sam(input_data, np_result), 'RMSE:',(rmse(input_data, np_result)), 'PSNR:',psnr(input_data, np_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6362b2abdb3b3049da6a7a3eff89e3934943f1b7bb3ae7d2ae0d964b4f04086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
